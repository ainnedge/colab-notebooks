{"cells":[{"cell_type":"markdown","source":["## Setup Environment"],"metadata":{"id":"qb9qKvDdMbNX"}},{"cell_type":"code","source":["# Install specific libraries\n","! pip install transformers\n","! pip install pycaret"],"metadata":{"id":"jYNPBqRnEdJT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679066777590,"user_tz":-330,"elapsed":651732,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}},"outputId":"501aa799-f0ce-49c5-8acf-1e12f928edc4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.1-py3-none-any.whl (6.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.2-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.2 tokenizers-0.13.2 transformers-4.27.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pycaret\n","  Downloading pycaret-2.3.10-py3-none-any.whl (320 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.2/320.2 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from pycaret) (1.4.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from pycaret) (1.1.1)\n","Collecting mlxtend>=0.17.0\n","  Downloading mlxtend-0.21.0-py2.py3-none-any.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting mlflow\n","  Downloading mlflow-2.2.2-py3-none-any.whl (17.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyLDAvis\n","  Downloading pyLDAvis-3.4.0-py3-none-any.whl (2.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting Boruta\n","  Downloading Boruta-0.3-py3-none-any.whl (56 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting kmodes>=0.10.1\n","  Downloading kmodes-0.12.2-py2.py3-none-any.whl (20 kB)\n","Collecting pyyaml<6.0.0\n","  Downloading PyYAML-5.4.1-cp39-cp39-manylinux1_x86_64.whl (630 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.1/630.1 KB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: textblob in /usr/local/lib/python3.9/dist-packages (from pycaret) (0.15.3)\n","Collecting pyod\n","  Downloading pyod-1.0.8.tar.gz (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.0/150.0 KB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cufflinks>=0.17.0 in /usr/local/lib/python3.9/dist-packages (from pycaret) (0.17.3)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.9/dist-packages (from pycaret) (7.9.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from pycaret) (3.7.1)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.9/dist-packages (from pycaret) (7.7.1)\n","Collecting imbalanced-learn==0.7.0\n","  Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.1/167.1 KB\u001b[0m \u001b[31m677.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scikit-plot\n","  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n","Requirement already satisfied: gensim<4.0.0 in /usr/local/lib/python3.9/dist-packages (from pycaret) (3.6.0)\n","Collecting lightgbm>=2.3.1\n","  Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scikit-learn==0.23.2\n","  Downloading scikit-learn-0.23.2.tar.gz (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from pycaret) (3.7)\n","Collecting spacy<2.4.0\n","  Downloading spacy-2.3.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wordcloud in /usr/local/lib/python3.9/dist-packages (from pycaret) (1.8.2.2)\n","Collecting numba<0.55\n","  Downloading numba-0.54.1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: plotly>=4.4.1 in /usr/local/lib/python3.9/dist-packages (from pycaret) (5.5.0)\n","Requirement already satisfied: yellowbrick>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from pycaret) (1.5)\n","Requirement already satisfied: pandas-profiling>=2.8.0 in /usr/local/lib/python3.9/dist-packages (from pycaret) (3.2.0)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.9/dist-packages (from pycaret) (0.12.2)\n","Collecting scipy<=1.5.4\n","  Downloading scipy-1.5.4-cp39-cp39-manylinux1_x86_64.whl (25.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting umap-learn\n","  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 KB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn==0.7.0->pycaret) (1.22.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==0.23.2->pycaret) (3.1.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from cufflinks>=0.17.0->pycaret) (1.15.0)\n","Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from cufflinks>=0.17.0->pycaret) (0.3.0)\n","Requirement already satisfied: setuptools>=34.4.1 in /usr/local/lib/python3.9/dist-packages (from cufflinks>=0.17.0->pycaret) (63.4.3)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.9/dist-packages (from gensim<4.0.0->pycaret) (6.3.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from IPython->pycaret) (0.7.5)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.9/dist-packages (from IPython->pycaret) (4.8.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.9/dist-packages (from IPython->pycaret) (5.7.1)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from IPython->pycaret) (2.0.10)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from IPython->pycaret) (0.2.0)\n","Collecting jedi>=0.10\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from IPython->pycaret) (4.4.2)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from IPython->pycaret) (2.6.1)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->pycaret) (3.6.2)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->pycaret) (0.2.0)\n","Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->pycaret) (5.3.4)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->pycaret) (3.0.5)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from lightgbm>=2.3.1->pycaret) (0.40.0)\n","Collecting mlxtend>=0.17.0\n","  Downloading mlxtend-0.20.0-py2.py3-none-any.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading mlxtend-0.19.0-py2.py3-none-any.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pycaret) (5.12.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pycaret) (0.11.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pycaret) (1.0.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pycaret) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pycaret) (2.8.2)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pycaret) (4.39.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pycaret) (8.4.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pycaret) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pycaret) (23.0)\n","Collecting numpy>=1.13.3\n","  Downloading numpy-1.20.3-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting llvmlite<0.38,>=0.37.0rc1\n","  Downloading llvmlite-0.37.0-cp39-cp39-manylinux2014_x86_64.whl (26.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.3/26.3 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->pycaret) (2022.7.1)\n","Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.9/dist-packages (from pandas-profiling>=2.8.0->pycaret) (4.65.0)\n","Requirement already satisfied: markupsafe~=2.1.1 in /usr/local/lib/python3.9/dist-packages (from pandas-profiling>=2.8.0->pycaret) (2.1.2)\n","Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.9/dist-packages (from pandas-profiling>=2.8.0->pycaret) (2.25.1)\n","Requirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.9/dist-packages (from pandas-profiling>=2.8.0->pycaret) (3.1.2)\n","Requirement already satisfied: pydantic>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas-profiling>=2.8.0->pycaret) (1.10.6)\n","Requirement already satisfied: htmlmin>=0.1.12 in /usr/local/lib/python3.9/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.1.12)\n","Requirement already satisfied: multimethod>=1.4 in /usr/local/lib/python3.9/dist-packages (from pandas-profiling>=2.8.0->pycaret) (1.9.1)\n","Requirement already satisfied: visions[type_image_path]==0.7.4 in /usr/local/lib/python3.9/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.7.4)\n","Requirement already satisfied: tangled-up-in-unicode==0.2.0 in /usr/local/lib/python3.9/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.2.0)\n","Requirement already satisfied: phik>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.12.3)\n","Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.9/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.5.2)\n","Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.9/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (3.0)\n","Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.9/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (22.2.0)\n","Requirement already satisfied: imagehash in /usr/local/lib/python3.9/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (4.3.1)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from plotly>=4.4.1->pycaret) (8.2.2)\n","Collecting plac<1.2.0,>=0.9.6\n","  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n","Collecting srsly<1.1.0,>=1.0.2\n","  Downloading srsly-1.0.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 KB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from spacy<2.4.0->pycaret) (0.10.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<2.4.0->pycaret) (2.0.7)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from spacy<2.4.0->pycaret) (0.7.9)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<2.4.0->pycaret) (1.0.9)\n","Collecting catalogue<1.1.0,>=0.0.7\n","  Downloading catalogue-1.0.2-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<2.4.0->pycaret) (3.0.8)\n","Collecting thinc<7.5.0,>=7.4.1\n","  Downloading thinc-7.4.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yellowbrick>=1.0.1\n","  Downloading yellowbrick-1.4-py3-none-any.whl (274 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.2/274.2 KB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading yellowbrick-1.3.post1-py3-none-any.whl (271 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.4/271.4 KB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading yellowbrick-1.3-py3-none-any.whl (271 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.3/271.3 KB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading yellowbrick-1.2.1-py3-none-any.whl (269 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.5/269.5 KB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow<12,>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from mlflow->pycaret) (9.0.0)\n","Collecting docker<7,>=4.0.0\n","  Downloading docker-6.0.1-py3-none-any.whl (147 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.5/147.5 KB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gunicorn<21\n","  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: entrypoints<1 in /usr/local/lib/python3.9/dist-packages (from mlflow->pycaret) (0.4)\n","Collecting shap<1,>=0.40\n","  Downloading shap-0.41.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (572 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.4/572.4 KB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gitpython<4,>=2.1.0\n","  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from mlflow->pycaret) (0.4.3)\n","Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from mlflow->pycaret) (1.4.46)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.9/dist-packages (from mlflow->pycaret) (8.1.3)\n","Collecting querystring-parser<2\n","  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n","Requirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.9/dist-packages (from mlflow->pycaret) (2.2.1)\n","Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.9/dist-packages (from mlflow->pycaret) (3.4.1)\n","Collecting alembic<2\n","  Downloading alembic-1.10.2-py3-none-any.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Flask<3 in /usr/local/lib/python3.9/dist-packages (from mlflow->pycaret) (2.2.3)\n","Requirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /usr/local/lib/python3.9/dist-packages (from mlflow->pycaret) (6.0.0)\n","Collecting databricks-cli<1,>=0.8.7\n","  Downloading databricks-cli-0.17.5.tar.gz (82 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.4/82.4 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.9/dist-packages (from mlflow->pycaret) (3.19.6)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk->pycaret) (2022.6.2)\n","Collecting pyLDAvis\n","  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.9/dist-packages (from pyLDAvis->pycaret) (2.8.4)\n","Collecting funcy\n","  Downloading funcy-1.18-py2.py3-none-any.whl (33 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from pyLDAvis->pycaret) (0.16.0)\n","Collecting sklearn\n","  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pynndescent>=0.5\n","  Downloading pynndescent-0.5.8.tar.gz (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting Mako\n","  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/dist-packages (from alembic<2->mlflow->pycaret) (4.5.0)\n","Collecting pyjwt>=1.7.0\n","  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n","Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->pycaret) (3.2.2)\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.9/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->pycaret) (0.8.10)\n","Collecting websocket-client>=0.32.0\n","  Downloading websocket_client-1.5.1-py3-none-any.whl (55 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting requests>=2.24.0\n","  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.9/dist-packages (from docker<7,>=4.0.0->mlflow->pycaret) (1.26.15)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.9/dist-packages (from Flask<3->mlflow->pycaret) (2.1.2)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.9/dist-packages (from Flask<3->mlflow->pycaret) (2.2.3)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow->pycaret) (3.15.0)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (6.2)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.9/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (6.1.12)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.10->IPython->pycaret) (0.8.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->pycaret) (0.2.6)\n","Collecting charset-normalizer<4,>=2\n","  Downloading charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2022.12.7)\n","Collecting slicer==0.0.7\n","  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow->pycaret) (2.0.2)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.9/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->pycaret) (6.3.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect->IPython->pycaret) (0.7.0)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (21.3.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (6.5.4)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (5.7.3)\n","Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (5.2.0)\n","Requirement already satisfied: Send2Trash>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (1.8.0)\n","Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (23.2.1)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (0.17.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (0.16.0)\n","Requirement already satisfied: PyWavelets in /usr/local/lib/python3.9/dist-packages (from imagehash->visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (1.4.1)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (3.1.1)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.9/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (21.2.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (4.9.2)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (0.2.2)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (1.2.1)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (1.5.0)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (0.7.2)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (0.7.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (6.0.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (0.8.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (4.9.3)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.9/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (4.3.3)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.9/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (2.16.3)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (0.19.3)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (1.15.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (2.4)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (0.5.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (2.21)\n","Building wheels for collected packages: scikit-learn, pyLDAvis, pyod, umap-learn, databricks-cli, pynndescent, sklearn\n","  Building wheel for scikit-learn (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for scikit-learn: filename=scikit_learn-0.23.2-cp39-cp39-linux_x86_64.whl size=24648958 sha256=f0e1dfbfc8d5b9b048166219deb2c45100d8f0b93979182562e2e02d38ed639a\n","  Stored in directory: /root/.cache/pip/wheels/5e/74/24/7e235ccf01765c0daa089c98cc823e9dc1383da5fe0ed7e224\n","  Building wheel for pyLDAvis (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyLDAvis: filename=pyLDAvis-3.3.1-py2.py3-none-any.whl size=136896 sha256=2a53ea8fd7f0f453697c15323a8c922a562818cdb1c2b8f06bc882577e07439c\n","  Stored in directory: /root/.cache/pip/wheels/57/a4/86/d10c6c2e0bf149fbc0afb0aa5a6528ac35b30a133a0270c477\n","  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyod: filename=pyod-1.0.8-py3-none-any.whl size=184054 sha256=46613ef70c6243a8c7006d8d9cb15b15b723cd4a031e99ce5d2c19859af64ff8\n","  Stored in directory: /root/.cache/pip/wheels/90/2b/16/c9baeb5fcd94a8a5bc4ea786fef2122f5b9ab3a61a7fc0303a\n","  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82830 sha256=735a60c78f7e794741cf1d158a56744f57308889d79de264ab02edc6555e2f60\n","  Stored in directory: /root/.cache/pip/wheels/f4/3e/1c/596d0a463d17475af648688443fa4846fef624d1390339e7e9\n","  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for databricks-cli: filename=databricks_cli-0.17.5-py3-none-any.whl size=143016 sha256=e736c31bb7eacbf6019f238e34d9e9b01d693d726ae403f47544b841c3d4122b\n","  Stored in directory: /root/.cache/pip/wheels/d1/ac/b1/2c75e46c6ffb00ed09b3c94577a1ea387b75289a2ee04f247d\n","  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pynndescent: filename=pynndescent-0.5.8-py3-none-any.whl size=55509 sha256=29b4df95dbf19767ebb018ff3ed81fd7a45112e5573da697b624db0632c9a617\n","  Stored in directory: /root/.cache/pip/wheels/b9/89/cc/59ab91ef5b21dc2ab3635528d7d227f49dfc9169905dcb959d\n","  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2955 sha256=aead91745d39a430c7e22469b11da1e218258d9654e17705f946ef7b27a68669\n","  Stored in directory: /root/.cache/pip/wheels/f8/e0/3d/9d0c2020c44a519b9f02ab4fa6d2a4a996c98d79ab2f569fa1\n","Successfully built scikit-learn pyLDAvis pyod umap-learn databricks-cli pynndescent sklearn\n","Installing collected packages: sklearn, plac, funcy, websocket-client, srsly, smmap, slicer, querystring-parser, pyyaml, pyjwt, numpy, Mako, llvmlite, jedi, gunicorn, charset-normalizer, catalogue, scipy, requests, numba, gitdb, alembic, thinc, scikit-learn, gitpython, docker, databricks-cli, yellowbrick, spacy, shap, scikit-plot, pyod, pynndescent, pyLDAvis, mlxtend, lightgbm, kmodes, imbalanced-learn, Boruta, umap-learn, mlflow, pycaret\n","  Attempting uninstall: srsly\n","    Found existing installation: srsly 2.4.6\n","    Uninstalling srsly-2.4.6:\n","      Successfully uninstalled srsly-2.4.6\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 6.0\n","    Uninstalling PyYAML-6.0:\n","      Successfully uninstalled PyYAML-6.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.22.4\n","    Uninstalling numpy-1.22.4:\n","      Successfully uninstalled numpy-1.22.4\n","  Attempting uninstall: llvmlite\n","    Found existing installation: llvmlite 0.39.1\n","    Uninstalling llvmlite-0.39.1:\n","      Successfully uninstalled llvmlite-0.39.1\n","  Attempting uninstall: catalogue\n","    Found existing installation: catalogue 2.0.8\n","    Uninstalling catalogue-2.0.8:\n","      Successfully uninstalled catalogue-2.0.8\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.10.1\n","    Uninstalling scipy-1.10.1:\n","      Successfully uninstalled scipy-1.10.1\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.25.1\n","    Uninstalling requests-2.25.1:\n","      Successfully uninstalled requests-2.25.1\n","  Attempting uninstall: numba\n","    Found existing installation: numba 0.56.4\n","    Uninstalling numba-0.56.4:\n","      Successfully uninstalled numba-0.56.4\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 8.1.9\n","    Uninstalling thinc-8.1.9:\n","      Successfully uninstalled thinc-8.1.9\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","  Attempting uninstall: yellowbrick\n","    Found existing installation: yellowbrick 1.5\n","    Uninstalling yellowbrick-1.5:\n","      Successfully uninstalled yellowbrick-1.5\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 3.4.4\n","    Uninstalling spacy-3.4.4:\n","      Successfully uninstalled spacy-3.4.4\n","  Attempting uninstall: mlxtend\n","    Found existing installation: mlxtend 0.14.0\n","    Uninstalling mlxtend-0.14.0:\n","      Successfully uninstalled mlxtend-0.14.0\n","  Attempting uninstall: lightgbm\n","    Found existing installation: lightgbm 2.2.3\n","    Uninstalling lightgbm-2.2.3:\n","      Successfully uninstalled lightgbm-2.2.3\n","  Attempting uninstall: imbalanced-learn\n","    Found existing installation: imbalanced-learn 0.8.1\n","    Uninstalling imbalanced-learn-0.8.1:\n","      Successfully uninstalled imbalanced-learn-0.8.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xarray-einstats 0.5.1 requires scipy>=1.6, but you have scipy 1.5.4 which is incompatible.\n","en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 2.3.9 which is incompatible.\n","confection 0.0.4 requires srsly<3.0.0,>=2.4.0, but you have srsly 1.0.6 which is incompatible.\n","cmdstanpy 1.1.0 requires numpy>=1.21, but you have numpy 1.20.3 which is incompatible.\n","arviz 0.15.1 requires scipy>=1.8.0, but you have scipy 1.5.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed Boruta-0.3 Mako-1.2.4 alembic-1.10.2 catalogue-1.0.2 charset-normalizer-3.1.0 databricks-cli-0.17.5 docker-6.0.1 funcy-1.18 gitdb-4.0.10 gitpython-3.1.31 gunicorn-20.1.0 imbalanced-learn-0.7.0 jedi-0.18.2 kmodes-0.12.2 lightgbm-3.3.5 llvmlite-0.37.0 mlflow-2.2.2 mlxtend-0.19.0 numba-0.54.1 numpy-1.20.3 plac-1.1.3 pyLDAvis-3.3.1 pycaret-2.3.10 pyjwt-2.6.0 pynndescent-0.5.8 pyod-1.0.8 pyyaml-5.4.1 querystring-parser-1.2.4 requests-2.28.2 scikit-learn-0.23.2 scikit-plot-0.3.7 scipy-1.5.4 shap-0.41.0 sklearn-0.0.post1 slicer-0.0.7 smmap-5.0.0 spacy-2.3.9 srsly-1.0.6 thinc-7.4.6 umap-learn-0.5.3 websocket-client-1.5.1 yellowbrick-1.2.1\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"HIFgZcfWlC8F","executionInfo":{"status":"ok","timestamp":1679066782357,"user_tz":-330,"elapsed":4785,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import pycaret\n","import transformers\n","from transformers import AutoModel, BertTokenizerFast\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import plot_confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import torch\n","import torch.nn as nn\n","# specify GPU\n","device = torch.device(\"cuda\")"]},{"cell_type":"code","source":["# Mount Google Drive - applicable, if working on Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Pfi1QUkuEss5","colab":{"base_uri":"https://localhost:8080/","height":365},"executionInfo":{"status":"error","timestamp":1679070821139,"user_tz":-330,"elapsed":4038814,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}},"outputId":"62ef1456-8048-4316-e8b7-d088007a0397"},"execution_count":4,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-dc37fa6b1a5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mount Google Drive - applicable, if working on Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m   )\n\u001b[0;32m--> 177\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    102\u001b[0m     ):\n\u001b[1;32m    103\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]},{"cell_type":"code","source":["# Set Working Directory - if working on Google Drive\n","%cd /content/drive/MyDrive/content\n","\n","# # Set Working Directory - if working on Local Machine\n","# import os\n","# os.chdir('/Users//replace_me')"],"metadata":{"id":"-xkkoUVsEu_w","executionInfo":{"status":"aborted","timestamp":1679070821145,"user_tz":-330,"elapsed":72,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load Dataset"],"metadata":{"id":"Ar3qNZz0MiGk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Gkv1hk-mr9Z","executionInfo":{"status":"aborted","timestamp":1679070821147,"user_tz":-330,"elapsed":71,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}}},"outputs":[],"source":["# Load Dataset\n","true_data = pd.read_csv('a1_True.csv')\n","fake_data = pd.read_csv('a2_Fake.csv')\n","\n","# Generate labels True/Fake under new Target Column in 'true_data' and 'fake_data'\n","true_data['Target'] = ['True']*len(true_data)\n","fake_data['Target'] = ['Fake']*len(fake_data)\n","\n","# Merge 'true_data' and 'fake_data', by random mixing into a single df called 'data'\n","data = true_data.append(fake_data).sample(frac=1).reset_index().drop(columns=['index'])\n","\n","# See how the data looks like\n","print(data.shape)\n","data.head()"]},{"cell_type":"code","source":["# Target column is made of string values True/Fake, let's change it to numbers 0/1 (Fake=1) \n","data['label'] = pd.get_dummies(data.Target)['Fake']"],"metadata":{"id":"u86aL9M0WA3T","executionInfo":{"status":"aborted","timestamp":1679070821148,"user_tz":-330,"elapsed":71,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.head()"],"metadata":{"id":"yt2qbRKOwz-H","executionInfo":{"status":"aborted","timestamp":1679070821148,"user_tz":-330,"elapsed":69,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6GR5qqqwoVAc","executionInfo":{"status":"aborted","timestamp":1679070821150,"user_tz":-330,"elapsed":67,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}}},"outputs":[],"source":["# Checking if our data is well balanced\n","label_size = [data['label'].sum(),len(data['label'])-data['label'].sum()]\n","plt.pie(label_size,explode=[0.1,0.1],colors=['firebrick','navy'],startangle=90,shadow=True,labels=['Fake','True'],autopct='%1.1f%%')"]},{"cell_type":"markdown","source":["## Train-test-split"],"metadata":{"id":"Zj5h7QbnZC0t"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3P9DYEq3y6pR","executionInfo":{"status":"aborted","timestamp":1679070821150,"user_tz":-330,"elapsed":67,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}}},"outputs":[],"source":["# Train-Validation-Test set split into 70:15:15 ratio\n","# Train-Temp split\n","train_text, temp_text, train_labels, temp_labels = train_test_split(data['title'], data['label'], \n","                                                                    random_state=2018, \n","                                                                    test_size=0.3, \n","                                                                    stratify=data['Target'])\n","# Validation-Test split\n","val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n","                                                                random_state=2018, \n","                                                                test_size=0.5, \n","                                                                stratify=temp_labels)"]},{"cell_type":"markdown","source":["## BERT Fine-tuning"],"metadata":{"id":"2ItKm0hDMujq"}},{"cell_type":"markdown","source":["### Load pretrained BERT Model"],"metadata":{"id":"HIkcURDhz2R0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6skrhdVzW0b","executionInfo":{"status":"aborted","timestamp":1679070821152,"user_tz":-330,"elapsed":69,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}}},"outputs":[],"source":["# Load BERT model and tokenizer via HuggingFace Transformers\n","bert = AutoModel.from_pretrained('bert-base-uncased')\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"]},{"cell_type":"markdown","source":["### Prepare Input Data"],"metadata":{"id":"H1G4xtl7dXBD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FDZx-O2xzcA_","executionInfo":{"status":"aborted","timestamp":1679070821153,"user_tz":-330,"elapsed":70,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}}},"outputs":[],"source":["# Plot histogram of the number of words in train data 'title'\n","seq_len = [len(title.split()) for title in train_text]\n","\n","pd.Series(seq_len).hist(bins = 40,color='firebrick')\n","plt.xlabel('Number of Words')\n","plt.ylabel('Number of texts')"]},{"cell_type":"code","source":["# BERT Tokeizer Functionality\n","sample_data = [\"Build fake news model.\", \n","               \"Using bert.\"]                                         # sample data\n","tokenized_sample_data = tokenizer.batch_encode_plus(sample_data,\n","                                                    padding=True)     # encode text\n","print(tokenized_sample_data)\n","\n","# Ref: https://huggingface.co/docs/transformers/preprocessing"],"metadata":{"id":"ry0ptLTW-Chy","executionInfo":{"status":"aborted","timestamp":1679070821153,"user_tz":-330,"elapsed":69,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rfwINnZozkyd","executionInfo":{"status":"aborted","timestamp":1679070821153,"user_tz":-330,"elapsed":69,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}}},"outputs":[],"source":["# Majority of titles above have word length under 15. So, we set max title length as 15\n","MAX_LENGHT = 15\n","# Tokenize and encode sequences in the train set\n","tokens_train = tokenizer.batch_encode_plus(\n","    train_text.tolist(),\n","    max_length = MAX_LENGHT,\n","    pad_to_max_length=True,\n","    truncation=True\n",")\n","# tokenize and encode sequences in the validation set\n","tokens_val = tokenizer.batch_encode_plus(\n","    val_text.tolist(),\n","    max_length = MAX_LENGHT,\n","    pad_to_max_length=True,\n","    truncation=True\n",")\n","# tokenize and encode sequences in the test set\n","tokens_test = tokenizer.batch_encode_plus(\n","    test_text.tolist(),\n","    max_length = MAX_LENGHT,\n","    pad_to_max_length=True,\n","    truncation=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jE9PI9_H0Moi","executionInfo":{"status":"aborted","timestamp":1679070821154,"user_tz":-330,"elapsed":69,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}}},"outputs":[],"source":["# Convert lists to tensors\n","train_seq = torch.tensor(tokens_train['input_ids'])\n","train_mask = torch.tensor(tokens_train['attention_mask'])\n","train_y = torch.tensor(train_labels.tolist())\n","\n","val_seq = torch.tensor(tokens_val['input_ids'])\n","val_mask = torch.tensor(tokens_val['attention_mask'])\n","val_y = torch.tensor(val_labels.tolist())\n","\n","test_seq = torch.tensor(tokens_test['input_ids'])\n","test_mask = torch.tensor(tokens_test['attention_mask'])\n","test_y = torch.tensor(test_labels.tolist())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oft-16jR0M6h","executionInfo":{"status":"aborted","timestamp":1679070821155,"user_tz":-330,"elapsed":69,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}}},"outputs":[],"source":["# Data Loader structure definition\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","batch_size = 32                                               #define a batch size\n","\n","train_data = TensorDataset(train_seq, train_mask, train_y)    # wrap tensors\n","train_sampler = RandomSampler(train_data)                     # sampler for sampling the data during training\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","                                                              # dataLoader for train set\n","val_data = TensorDataset(val_seq, val_mask, val_y)            # wrap tensors\n","val_sampler = SequentialSampler(val_data)                     # sampler for sampling the data during training\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n","                                                              # dataLoader for validation set"]},{"cell_type":"markdown","source":["### Freeze Layers"],"metadata":{"id":"VkHiWeqop3Q_"}},{"cell_type":"code","source":["# Freezing the parameters and defining trainable BERT structure\n","for param in bert.parameters():\n","    param.requires_grad = False    # false here means gradient need not be computed"],"metadata":{"id":"dH-wI1yhzQkD","executionInfo":{"status":"aborted","timestamp":1679070821158,"user_tz":-330,"elapsed":72,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Define Model Architecture"],"metadata":{"id":"XAJPyGH4zaRZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5oC6f5jD0vm0","executionInfo":{"status":"aborted","timestamp":1679070821160,"user_tz":-330,"elapsed":73,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}}},"outputs":[],"source":["class BERT_Arch(nn.Module):\n","    def __init__(self, bert):  \n","      super(BERT_Arch, self).__init__()\n","      self.bert = bert   \n","      self.dropout = nn.Dropout(0.1)            # dropout layer\n","      self.relu =  nn.ReLU()                    # relu activation function\n","      self.fc1 = nn.Linear(768,512)             # dense layer 1\n","      self.fc2 = nn.Linear(512,2)               # dense layer 2 (Output layer)\n","      self.softmax = nn.LogSoftmax(dim=1)       # softmax activation function\n","    def forward(self, sent_id, mask):           # define the forward pass  \n","      cls_hs = self.bert(sent_id, attention_mask=mask)['pooler_output']\n","                                                # pass the inputs to the model\n","      x = self.fc1(cls_hs)\n","      x = self.relu(x)\n","      x = self.dropout(x)\n","      x = self.fc2(x)                           # output layer\n","      x = self.softmax(x)                       # apply softmax activation\n","      return x\n","\n","model = BERT_Arch(bert)\n","# Defining the hyperparameters (optimizer, weights of the classes and the epochs)\n","# Define the optimizer\n","from transformers import AdamW\n","optimizer = AdamW(model.parameters(),\n","                  lr = 1e-5)          # learning rate\n","# Define the loss function\n","cross_entropy  = nn.NLLLoss() \n","# Number of training epochs\n","epochs = 2"]},{"cell_type":"markdown","source":["### Define Train & Evaluate Function"],"metadata":{"id":"LGFpP494zgLh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BEG81NvL1Rt9","executionInfo":{"status":"aborted","timestamp":1679070821162,"user_tz":-330,"elapsed":75,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}}},"outputs":[],"source":["# Defining training and evaluation functions\n","def train():  \n","  model.train()\n","  total_loss, total_accuracy = 0, 0\n","  \n","  for step,batch in enumerate(train_dataloader):                # iterate over batches\n","    if step % 50 == 0 and not step == 0:                        # progress update after every 50 batches.\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","    batch = [r for r in batch]                                  # push the batch to gpu\n","    sent_id, mask, labels = batch \n","    model.zero_grad()                                           # clear previously calculated gradients\n","    preds = model(sent_id, mask)                                # get model predictions for current batch\n","    loss = cross_entropy(preds, labels)                         # compute loss between actual & predicted values\n","    total_loss = total_loss + loss.item()                       # add on to the total loss\n","    loss.backward()                                             # backward pass to calculate the gradients\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)     # clip gradients to 1.0. It helps in preventing exploding gradient problem\n","    optimizer.step()                                            # update parameters\n","    preds=preds.detach().cpu().numpy()                          # model predictions are stored on GPU. So, push it to CPU\n","\n","  avg_loss = total_loss / len(train_dataloader)                 # compute training loss of the epoch  \n","                                                                # reshape predictions in form of (# samples, # classes)\n","  return avg_loss                                 # returns the loss and predictions\n","\n","def evaluate():  \n","  print(\"\\nEvaluating...\")  \n","  model.eval()                                    # Deactivate dropout layers\n","  total_loss, total_accuracy = 0, 0  \n","  for step,batch in enumerate(val_dataloader):    # Iterate over batches  \n","    if step % 50 == 0 and not step == 0:          # Progress update every 50 batches.     \n","                                                  # Calculate elapsed time in minutes.\n","                                                  # Elapsed = format_time(time.time() - t0)\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n","                                                  # Report progress\n","    batch = [t for t in batch]                    # Push the batch to GPU\n","    sent_id, mask, labels = batch\n","    with torch.no_grad():                         # Deactivate autograd\n","      preds = model(sent_id, mask)                # Model predictions\n","      loss = cross_entropy(preds,labels)          # Compute the validation loss between actual and predicted values\n","      total_loss = total_loss + loss.item()\n","      preds = preds.detach().cpu().numpy()\n","  avg_loss = total_loss / len(val_dataloader)         # compute the validation loss of the epoch\n","  return avg_loss"]},{"cell_type":"markdown","source":["### Model training"],"metadata":{"id":"IARpecoUzloO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"uSN0ZPiW1d-e","executionInfo":{"status":"aborted","timestamp":1679070821163,"user_tz":-330,"elapsed":76,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}}},"outputs":[],"source":["# Train and predict\n","best_valid_loss = float('inf')\n","train_losses=[]                   # empty lists to store training and validation loss of each epoch\n","valid_losses=[]\n","\n","for epoch in range(epochs):     \n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))     \n","    train_loss = train()                       # train model\n","    valid_loss = evaluate()                    # evaluate model\n","    if valid_loss < best_valid_loss:              # save the best model\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'c2_new_model_weights.pt')\n","    train_losses.append(train_loss)               # append training and validation loss\n","    valid_losses.append(valid_loss)\n","    \n","    print(f'\\nTraining Loss: {train_loss:.3f}')\n","    print(f'Validation Loss: {valid_loss:.3f}')"]},{"cell_type":"markdown","source":["### Model performance"],"metadata":{"id":"Qp7jw9a6qiPt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1fVcPQH5oTc6","executionInfo":{"status":"aborted","timestamp":1679070821163,"user_tz":-330,"elapsed":74,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}}},"outputs":[],"source":["# load weights of best model\n","path = 'c1_fakenews_weights.pt'\n","model.load_state_dict(torch.load(path))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aRgRYquAoWbu","executionInfo":{"status":"aborted","timestamp":1679070821164,"user_tz":-330,"elapsed":72,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}}},"outputs":[],"source":["with torch.no_grad():\n","  preds = model(test_seq, test_mask)\n","  preds = preds.detach().cpu().numpy()\n","\n","preds = np.argmax(preds, axis = 1)\n","print(classification_report(test_y, preds))"]},{"cell_type":"markdown","source":["## Fake News Predictions"],"metadata":{"id":"P95XPCMoq8nN"}},{"cell_type":"code","source":["# # load weights of best model\n","# path = 'c1_fakenews_weights.pt'\n","# model.load_state_dict(torch.load(path))"],"metadata":{"id":"hVr9XJT14dO2","executionInfo":{"status":"aborted","timestamp":1679070821165,"user_tz":-330,"elapsed":70,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# testing on unseen data\n","unseen_news_text = [\"Donald Trump Sends Out Embarrassing New Year’s Eve Message; This is Disturbing\",     # Fake\n","                    \"WATCH: George W. Bush Calls Out Trump For Supporting White Supremacy\",               # Fake\n","                    \"U.S. lawmakers question businessman at 2016 Trump Tower meeting: sources\",           # True\n","                    \"Trump administration issues new rules on U.S. visa waivers\"                          # True\n","                    ]\n","\n","# tokenize and encode sequences in the test set\n","MAX_LENGHT = 15\n","tokens_unseen = tokenizer.batch_encode_plus(\n","    unseen_news_text,\n","    max_length = MAX_LENGHT,\n","    pad_to_max_length=True,\n","    truncation=True\n",")\n","\n","unseen_seq = torch.tensor(tokens_unseen['input_ids'])\n","unseen_mask = torch.tensor(tokens_unseen['attention_mask'])\n","\n","with torch.no_grad():\n","  preds = model(unseen_seq, unseen_mask)\n","  preds = preds.detach().cpu().numpy()\n","\n","preds = np.argmax(preds, axis = 1)\n","preds"],"metadata":{"id":"vooQxtj5UBt-","executionInfo":{"status":"aborted","timestamp":1679070821165,"user_tz":-330,"elapsed":68,"user":{"displayName":"sriram sriram","userId":"12587440421639375558"}}},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1JT0G0L2xYx_CGQ0d8h1SFuA5yOlJLeYf","timestamp":1679052545941},{"file_id":"1Ui6B2rToJMqpzACJqYG8D7pMpG0vdDgK","timestamp":1662535690096}],"collapsed_sections":["qb9qKvDdMbNX","Ar3qNZz0MiGk","Zj5h7QbnZC0t","HIkcURDhz2R0","H1G4xtl7dXBD","VkHiWeqop3Q_","XAJPyGH4zaRZ","LGFpP494zgLh","IARpecoUzloO","Qp7jw9a6qiPt","P95XPCMoq8nN"]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}